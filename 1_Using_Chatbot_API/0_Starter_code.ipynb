{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyond GPT-4: What's New?</td>\n",
       "      <td>LLM Variants and Meta's Open Source Before she...</td>\n",
       "      <td>https://pub.towardsai.net/beyond-gpt-4-whats-n...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Building a Q&amp;A Bot over Private Documents with...</td>\n",
       "      <td>Private data to be used The example provided c...</td>\n",
       "      <td>https://pub.towardsai.net/building-a-q-a-bot-o...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enhancing E-commerce Product Search Using LLMs</td>\n",
       "      <td>Problem Statement Despite the pioneers like Am...</td>\n",
       "      <td>https://pub.towardsai.net/enhancing-e-commerce...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploring Large Language Models -Part 3</td>\n",
       "      <td>Fine Tuning on Custom Domain Data All the popu...</td>\n",
       "      <td>https://pub.towardsai.net/exploring-large-lang...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fine-Tuning a Llama-2 7B Model for Python Code...</td>\n",
       "      <td>New Llama-2 model In mid-July, Meta released i...</td>\n",
       "      <td>https://pub.towardsai.net/fine-tuning-a-llama-...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Foundation Models: Scaling Large Language Models</td>\n",
       "      <td>New Moore's Laws Achieving Zettascale Computin...</td>\n",
       "      <td>https://pub.towardsai.net/foundation-models-37...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPTQ Quantization on a Llama 2 7B Fine-Tuned M...</td>\n",
       "      <td>GPTQ: Post-training quantization on generative...</td>\n",
       "      <td>https://pub.towardsai.net/gptq-quantization-on...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLaMA by Meta leaked by an anonymous forum: Qu...</td>\n",
       "      <td>LLaMA: Meta's new AI tool According to the off...</td>\n",
       "      <td>https://pub.towardsai.net/llama-by-meta-leaked...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLaMA-GPT4All: Simplified Local ChatGPT</td>\n",
       "      <td>Introduce GPT4All GPT4All is a large language ...</td>\n",
       "      <td>https://pub.towardsai.net/llama-gpt4all-simpli...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inside Code Llama: Meta AI's Entrance in the C...</td>\n",
       "      <td>Inside Code Llama The release of Code Llama do...</td>\n",
       "      <td>https://pub.towardsai.net/inside-code-llama-me...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Meta's Llama 2: Revolutionizing Open Source La...</td>\n",
       "      <td>I. Llama 2: Revolutionizing Commercial Use Unl...</td>\n",
       "      <td>https://pub.towardsai.net/metas-llama-2-revolu...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Generative AI Revolution: Exploring the Cu...</td>\n",
       "      <td>What is Generative AI? Generative AI is a subf...</td>\n",
       "      <td>https://pub.towardsai.net/the-generative-ai-re...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Building Intuition on the Concepts behind LLMs...</td>\n",
       "      <td>Neural Networks LLMs like ChatGPT are trained ...</td>\n",
       "      <td>https://pub.towardsai.net/building-intuition-o...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WizardCoder: Why It's the Best Coding Model Ou...</td>\n",
       "      <td>What Sets WizardCoder Apart One might wonder w...</td>\n",
       "      <td>https://pub.towardsai.net/wizardcoder-why-its-...</td>\n",
       "      <td>towards_ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                           Beyond GPT-4: What's New?   \n",
       "1   Building a Q&A Bot over Private Documents with...   \n",
       "2      Enhancing E-commerce Product Search Using LLMs   \n",
       "3             Exploring Large Language Models -Part 3   \n",
       "4   Fine-Tuning a Llama-2 7B Model for Python Code...   \n",
       "5    Foundation Models: Scaling Large Language Models   \n",
       "6   GPTQ Quantization on a Llama 2 7B Fine-Tuned M...   \n",
       "7   LLaMA by Meta leaked by an anonymous forum: Qu...   \n",
       "8             LLaMA-GPT4All: Simplified Local ChatGPT   \n",
       "9   Inside Code Llama: Meta AI's Entrance in the C...   \n",
       "10  Meta's Llama 2: Revolutionizing Open Source La...   \n",
       "11  The Generative AI Revolution: Exploring the Cu...   \n",
       "12  Building Intuition on the Concepts behind LLMs...   \n",
       "13  WizardCoder: Why It's the Best Coding Model Ou...   \n",
       "\n",
       "                                              content  \\\n",
       "0   LLM Variants and Meta's Open Source Before she...   \n",
       "1   Private data to be used The example provided c...   \n",
       "2   Problem Statement Despite the pioneers like Am...   \n",
       "3   Fine Tuning on Custom Domain Data All the popu...   \n",
       "4   New Llama-2 model In mid-July, Meta released i...   \n",
       "5   New Moore's Laws Achieving Zettascale Computin...   \n",
       "6   GPTQ: Post-training quantization on generative...   \n",
       "7   LLaMA: Meta's new AI tool According to the off...   \n",
       "8   Introduce GPT4All GPT4All is a large language ...   \n",
       "9   Inside Code Llama The release of Code Llama do...   \n",
       "10  I. Llama 2: Revolutionizing Commercial Use Unl...   \n",
       "11  What is Generative AI? Generative AI is a subf...   \n",
       "12  Neural Networks LLMs like ChatGPT are trained ...   \n",
       "13  What Sets WizardCoder Apart One might wonder w...   \n",
       "\n",
       "                                                  url      source  \n",
       "0   https://pub.towardsai.net/beyond-gpt-4-whats-n...  towards_ai  \n",
       "1   https://pub.towardsai.net/building-a-q-a-bot-o...  towards_ai  \n",
       "2   https://pub.towardsai.net/enhancing-e-commerce...  towards_ai  \n",
       "3   https://pub.towardsai.net/exploring-large-lang...  towards_ai  \n",
       "4   https://pub.towardsai.net/fine-tuning-a-llama-...  towards_ai  \n",
       "5   https://pub.towardsai.net/foundation-models-37...  towards_ai  \n",
       "6   https://pub.towardsai.net/gptq-quantization-on...  towards_ai  \n",
       "7   https://pub.towardsai.net/llama-by-meta-leaked...  towards_ai  \n",
       "8   https://pub.towardsai.net/llama-gpt4all-simpli...  towards_ai  \n",
       "9   https://pub.towardsai.net/inside-code-llama-me...  towards_ai  \n",
       "10  https://pub.towardsai.net/metas-llama-2-revolu...  towards_ai  \n",
       "11  https://pub.towardsai.net/the-generative-ai-re...  towards_ai  \n",
       "12  https://pub.towardsai.net/building-intuition-o...  towards_ai  \n",
       "13  https://pub.towardsai.net/wizardcoder-why-its-...  towards_ai  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the necessary data for the RAG exercise\n",
    "import pandas as pd\n",
    "\n",
    "# Downloading and loading the mini blog dataset\n",
    "url = \"https://raw.githubusercontent.com/AlaFalaki/tutorial_notebooks/main/data/mini-llama-articles.csv\"\n",
    "mini_dataset = pd.read_csv(url)\n",
    "\n",
    "# Displaying the first few entries (run in a Jupyter Notebook)\n",
    "mini_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset.to_csv(\"mini-llama-articles.csv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
